
# Project 1 - Provisioning Data Processing Infrastructure with AWS EMR and Apache Flink

# Create a bucket in S3 called proj-bucket<account-id> and configure it in the emr.tf file

# Initialize Terraform
terraform init

# Create the Plan and save it to disk
terraform plan -var-file config.tfvars -out terraform.tfplan

# Execute apply with the variables file (with auto-approve)
terraform apply -auto-approve -var-file config.tfvars

# Execute apply with the variables file (without auto-approve)
terraform apply -var-file config.tfvars

# SSH connection to the cluster master
# In the Docker container, navigate to the folder where the keys created during the cluster deployment are located

# Adjust the privilege of the private key
chmod 400 deployer

# Connect via SSH (replace the address below with your cluster's)
ssh -i deployer hadoop@ec2-3-14-29-59.us-east-2.compute.amazonaws.com


# Create the Plan for destruction and save it to disk
terraform plan -destroy -var-file config.tfvars -out terraform.tfplan

# Execute the destroy
terraform apply terraform.tfplan